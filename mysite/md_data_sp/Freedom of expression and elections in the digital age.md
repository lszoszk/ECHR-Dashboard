# **Advance edited version** Distr.: General

11 June 2025

Original: English

# **Human Rights Council**

**Fifty-ninth session** 16 June–11 July 2025 Agenda item 3 **Promotion and protection of all human rights, civil, political, economic, social and cultural rights, including the right to development**

# **Freedom of expression and elections in the digital age**

# **Report of the Special Rapporteur on the promotion and protection of the right to freedom of opinion and expression, Irene Khan**\\*

*Summary*

In the present report, submitted pursuant to Human Rights Council resolution 52/9, the Special Rapporteur on the promotion and protection of the right to freedom of opinion and expression, Irene Khan, examines the vital role of freedom of opinion and expression in ensuring free and fair elections. She identifies the key vulnerabilities of freedom of expression during elections, including an upsurge in disinformation and hate speech in polarized political contexts, the backsliding of social media platforms on their commitments to safety and electoral integrity and the weakening of traditional news media. The Special Rapporteur concludes that the decline in freedom of expression must be reversed if public trust in elections is to be restored.

Drawing on international law and good practices, she makes specific recommendations to States, political parties and companies to strengthen freedom of expression in electoral contexts.

<sup>\*</sup> The present report was submitted to the conference services for processing after the deadline so as to include the most recent information.

![](_page_0_Picture_12.jpeg)

# **I. Introduction**

1. When freedom of expression is suppressed, electoral processes are endangered and public trust in elections suffers. In 2024, more than half of the world's voting age population, living in over 50 countries ranging from liberal democracies to electoral autocracies, went to the polls to choose their national, regional and local leaders. According to a survey conducted in 2023 in 19 countries with varied political systems, just over half of respondents believed that elections in their country had been free and fair.<sup>1</sup> A related survey found that freedom of expression and electoral integrity were two of the top elements that were in global decline.

2. If public confidence in elections is to be restored, the decline in freedom of expression must be reversed. The right to freedom of opinion and expression is a central pillar of democratic societies and a guarantor of free and fair election processes.<sup>2</sup> It empowers citizens to obtain information on the electoral process and to debate, discuss and make informed decisions on their choice of representatives. It allows candidates and political parties to campaign on the issues at stake in the elections. It enables the media and civil society to inform the public, scrutinize candidates and their party platforms and report on the integrity of the electoral process. By throwing light on the electoral process, the right to freedom of opinion and expression helps to build public trust in electoral outcomes.

3. Election integrity and information integrity are closely connected. Safe, free and fair elections require healthy, open information spaces in which accurate and independent information is easily accessible to the electorate. Increasingly, however, information spaces have come under severe strain during elections for two main reasons. Firstly, populist politicians eager to win elections at all costs and authoritarian Governments intent on holding on to power have resorted to information manipulation.

4. Secondly, digital technology and platforms have enabled and amplified those tendencies into a tsunami of disinformation, misinformation and hate speech.<sup>3</sup> The consequences have been dire. Political opponents, minorities, migrants and other marginalized groups have been targeted, vilified, threatened and attacked by State and non-State actors. Journalists and human rights defenders have been suppressed ruthlessly by Governments, often in the name of fighting disinformation. Politics has become polarized and democratic processes have been disrupted and democratic institutions, including elections, delegitimized.

5. The report is focused on the key vulnerabilities of the right to freedom of expression in electoral contexts. It contains an examination of the upsurge of information manipulation in politically polarized contexts, its impact on individuals, institutions and electoral environments and its role in the decline of traditional news media. The report also contains an analysis of the responses of States and companies to those challenges in the light of their international human rights obligations and includes recommendations for strengthening freedom of expression with a view to restoring public trust in elections.

6. The Special Rapporteur coordinated her work closely with the Special Rapporteur on the rights to freedom of peaceful assembly and association, who is also presenting a report on elections to the Human Rights Council at its fifty-ninth session.

7. The present report has benefited from consultations led by the Special Rapporteur over the past year with a wide range of stakeholders, including civil society organizations, electoral institutions, human rights defenders, journalists and representatives of social media companies. In addition to in-person and online meetings, the Special Rapporteur convened regional workshops in Addis Ababa, Bangkok, Santiago and Istanbul, Türkiye. She received 59 written contributions from States, civil society organizations, companies, international organizations and experts in response to her call for submissions.<sup>4</sup> She is grateful to all stakeholders for their engagement and valuable contributions.

<sup>1</sup> See International Institute for Democracy and Electoral Assistance, *The Global State of Democracy: Strengthening the Legitimacy of Elections in a Time of Radical Uncertainty* (Stockholm, 2024).

<sup>2</sup> [A/HRC/26/30,](https://docs.un.org/en/A/HRC/26/30) para. 10.

<sup>3</sup> For definitions of disinformation and misinformation, see [A/HRC/47/25,](https://docs.un.org/en/A/HRC/47/25) paras. 9–14. In the present report, disinformation is understood as false or manipulated information that causes or is intended to cause harm.

# **II. Electoral information landscape: trends and challenges**

### **A. Information manipulation: who is behind it, who is harmed by it**

8. In recent years, elections have been marked by high levels of information manipulation, instigated by both States and populist politicians in office or seeking election, enabled and amplified by digital platforms and feeding on the frustrations and grievances of growing numbers of people affected by economic deprivation, political disenfranchisement and social inequalities. The trend is alarming, degrading the information environment, fomenting hatred and violence and disrupting and delegitimizing democratic processes and institutions. The life cycle of electoral disinformation is not limited to the polling but begins long before and persists long after the elections, tainting political discourse and polarizing democratic societies. The goal is to harm political opponents, restrict voter participation, sow doubt about the electoral process and its outcomes and, ultimately, to erode democracy.

9. While information manipulation is most frequently home-grown, there is sometimes evidence of interference from abroad aimed at influencing the politics and polls in countries deemed to be strategically important to foreign powers. One study attributed a staggering nearly 60 per cent of disinformation campaigns on the African continent to foreign, non-African State sponsors.<sup>5</sup> Some States, including Australia, Mexico, Spain and Switzerland, have increased efforts to prevent interference from abroad in their elections.<sup>6</sup>

10. Information manipulation is frequently used as a tactic to restrict the participation of opposition candidates. Disinformation and harmful speech have also been utilized in highly visible ways against minorities and marginalized groups to deter their participation in elections, especially women,<sup>7</sup> religious minorities,<sup>8</sup> lesbian, gay, bisexual and transgender persons<sup>9</sup> and internally displaced persons.<sup>10</sup>

11. Political rhetoric expressing hatred and stigmatizing and dehumanizing people for their ethnicity, race, religion, language, sex, gender or sexual orientation has become widespread, even in liberal democracies. The impact of racist and xenophobic discourse becomes even greater and more harmful in electoral contexts.<sup>11</sup> Some politicians weaponize their freedom of expression to vilify, disparage and exclude minority or critical voices.<sup>12</sup> The weaponization often occurs under the pretext of promoting a free and open information environment in which efforts to denounce or prohibit hate speech are depicted as censorship.

12. Women face extremely high levels of gender-based violence and gendered disinformation, both online and offline, in their roles as politicians, candidates, voters, election officials, judges, journalists, human rights defenders or members of women's groups or civil society organizations. The objective is to silence their voices, discredit their work and drive them out of public life.<sup>13</sup> The trend is deeply worrying, given that women are already underrepresented in public life. Attacks frequently come from the coordinated actions of trolls and bots and include the doxing of personal data, fake stories, humiliating or sexually charged images and deepfakes, <sup>14</sup> often aimed at framing women as untrustworthy, unintelligent, emotional, angry, crazy or hypersexual.

<sup>4</sup> Submissions will be available at https://www.ohchr.org/en/calls-for-input/2025/call-submissionsthematic-report-freedom-expression-and-elections-digital-age.

<sup>5</sup> See Africa Centre for Strategic Studies, "Mapping a surge of disinformation in Africa", 13 March 2024.

<sup>6</sup> See submissions from Australia, Mexico, Spain and Switzerland.

</span><sup>7</sup> Se[e A/78/260.](https://docs.un.org/en/A/78/260)

</span><sup>8</sup> See communication PAK 3/2023. All communications cited in the present report are available at https://spcommreports.ohchr.org/Tmsearch/TMDocuments.

</span><sup>9</sup> [A/79/151,](https://docs.un.org/en/A/79/151) para. 35.

</span><sup>10</sup> [A/HRC/50/24,](https://docs.un.org/en/A/HRC/50/24) para. 63.

</span><sup>11</sup> European Court of Human Rights, *Sanchez v. France*, Application No. 45581/15, Judgment, 15 May 2023, para. 176.

</span><sup>12</sup> [A/HRC/56/53/Add.2,](https://docs.un.org/en/A/HRC/56/53/Add.2) para. 22.

</span><sup>13</sup> [A/78/288,](https://docs.un.org/en/A/78/288) para. 40; and communication KEN 2/2018.

13. Electoral violence is the most dangerous way of chilling political participation. It often starts with divisive statements and hate speech that either originate online or spread virally. In elections in some countries in 2024, divisive, incendiary and hateful statements by senior political leaders went viral and are believed to have instigated deadly violence against minorities.<sup>15</sup> In the 2023 elections in the Democratic Republic of the Congo, online speech was identified as a key contributor to electoral violence in which 19 people died.<sup>16</sup>

14. Efforts to spread false or misleading information about electoral procedures can disenfranchise voters. For instance, in Mexico, disinformation campaigns prior to election day left many voters unsure about how to mark their ballots.<sup>17</sup>

15. Targeting electoral officials hinders their ability to monitor, report and denounce irregularities. In recent elections, the scale and severity of disinformation targeting electoral bodies and observers have escalated.<sup>18</sup> For instance, the 2023 elections in both Guatemala and Zimbabwe saw extensive coordinated disinformation campaigns against independent observers.<sup>19</sup>

16. In recent years, high-profile disinformation campaigns have undermined public trust in election results, for instance in Brazil, South Africa and the United States of America.<sup>20</sup> Disinformation about electoral outcomes is dangerous because it can incite violence. In the United States, false claims on social media by the President, Donald Trump, regarding the legitimacy of the 2020 election results encouraged violent, extremist groups to invade the United States Capitol, disrupting the confirmation of the election results and causing dozens of injuries and five deaths.<sup>21</sup>

### **B. Social media: users and influencers**

17. Social media is a leading vector of disinformation and hate speech.<sup>22</sup> A survey of 16 countries in 2024 by the United Nations Educational, Scientific and Cultural Organization and Ipsos found that social media surpassed television as the primary source of news, with media websites in third place.<sup>23</sup> That has serious implications for elections.

18. Politicians increasingly use direct communication and social media to reach a wider audience and convey the image of being "one of the people". For example, podcasts were credited with tilting the scales of the 2024 elections in the United States in favour of Mr. Trump.<sup>24</sup>

<sup>14</sup> Nina Jankowicz and others, *It's Everyone's Problem: Mainstreaming Responses to Technology-Facilitated Gender-Based Violence* (New York, School of International and Public Affairs, Columbia University, 2024), p. 4.

<sup>15</sup> See communication IND 5/2024.

<sup>16</sup> See Bulanda T. Nkhowani, "Tech harms during elections in Africa", Digital Action, 12 June 2024.

<sup>17</sup> See Bruna Martins dos Santos, "Mexico's 2024 elections: a historic and contentious vote", Digital Action, 7 June 2024.

<sup>18</sup> European Commission for Democracy through Law, "Report on election observers as human rights defenders", 11 December 2024, paras. 56 and 109.

<sup>19</sup> See European Union Election Observation Mission, *Zimbabwe 2023: Harmonised Elections, 23 August 2023*, Final Report; and *Guatemala 2023: General Elections, 25 June 2023, and Presidential Run-Off, 20 August 2023*, Final Report.

<sup>20</sup> See submissions from Freedom House and from Conectas Direitos Humanos and Article 19: International Centre against Censorship (Brazil and South America).

<sup>21</sup> See communication USA 3/2021.

<sup>22</sup> Se[e A/HRC/47/25.](https://docs.un.org/en/A/HRC/47/25)

<sup>23</sup> See https://www.ipsos.com/en/elections-social-media-battle-against-disinformation-and-trust-issues.

<sup>24</sup> See "Joe Rogan and the Fifth Estate: how the podcaster and a group of cable news exiles became more powerful than traditional media", *Variety*, 13 November 2024.

19. For women in politics, social media is a double-edged sword.<sup>25</sup> On the one hand, it provides them with important avenues for direct communication with the public, bypassing traditional media, which is often gender-biased. On the other, it exposes them to vicious online disinformation, harassment and gender-based violence.<sup>26</sup>

20. As digital technology advances, electoral communications are evolving beyond the large social media platforms. Political parties are increasingly using mobile messaging applications, such as WhatsApp, Telegram, Viber and WeChat. In India, the ruling Bharatiya Janata Party operated at least 5 million WhatsApp groups to spread political communications rapidly and widely.<sup>27</sup> Closed communication platforms raise distinct challenges with regard to disinformation. In Zimbabwe, WhatsApp was the channel of choice for electoral disinformation due to its broad reach. <sup>28</sup> Telegram, which takes a hands-off approach to content moderation, is known for hosting group chats led by extremist groups, including those promoting electoral violence.<sup>29</sup> Political content is also increasingly being consumed on new communication platforms popular with gamers, such as Discord and Twitch, which have become vectors of electoral disinformation.

21. Social media has helped to enhance the political engagement of young people but also has exposed them to the toxic effects of online disinformation. Young people, particularly first-time voters, can be highly vulnerable to disinformation on social media. In the United States, almost half of those under the age of 30 years commonly use social media for political news.<sup>30</sup> In Indonesia, where Generation Z makes up over a quarter of the population, political actors have successfully engaged with that age group on Instagram using memes and humour.<sup>31</sup>

22. The popularity of social media among young people and its facility in reaching large audiences have given rise to a novel media figure: the influencer. Influencers, who may attract from a few thousand to several million viewers, post content across social media, video and podcast platforms on various lifestyle issues and are perceived by their followers as having an "authentic" voice. Politicians and candidates are increasingly engaging with influencers to amplify their messages. Influencers played major roles in recent elections and political campaigns in a wide range of countries, including Belgium,<sup>32</sup> Mexico,<sup>33</sup> Nigeria<sup>34</sup> and the United States.<sup>35</sup> The 2024 election in India was nicknamed the "YouTube election", given the ruling party's unprecedented use of YouTube influencers.<sup>36</sup>

23. While influencers have broadened political engagement, they pose significant risks. Unlike journalists, influencers are not bound by professional standards, rules or ethics. They are not obliged to provide balanced views, check facts or disclose affiliations. Influencers may also be susceptible to coercion by political candidates. At least 30 per cent of influencers surveyed in Bangladesh and India claimed to have been intimidated into featuring political candidates in their content.<sup>37</sup>

<sup>25</sup> See Lucina Di Meco, *#She Persisted: Women, Politics & Power in the New Media World*, (The Wilson Center, 2019).

<sup>26</sup> [A/78/288,](https://docs.un.org/en/A/78/288) para. 40.

<sup>27</sup> See Shristi Jaswal, "Inside the BJP's WhatsApp machine", *Rest of World*, 15 May 2024.

<sup>28</sup> See Bulanda T. Nkhowani, "Tech harms during elections in Africa", Digital Action, 12 June 2024.

<sup>29</sup> See Global Project against Hate and Extremism, "Online chatter about the election contains warning signs for violence", 28 October 2024.

<sup>30</sup> See https://www.pewresearch.org/journalism/2024/10/10/where-americans-turn-for-election-news.

<sup>31</sup> See Alifa Nur Fitri and others, "Gen Z voter behavior in the 2024 presidential election: a virtual ethnographic study on the Instagram accounts of presidential candidates", *Islamic Communication Journal*, vol. 8, No. 2 (2023).

<sup>32</sup> See Khushbu Agrawal, "Navigating the wild west of online campaign finance: how Mexico and Belgium are coping", International Institute for Democracy and Electoral Assistance, 13 March 2023.

<sup>33</sup> Ibid.

<sup>34</sup> See Temple Uwalaka and others, "Social media influencers and political influence operations: the Data Boys example in Nigeria", *Public Relations Inquiry*, vol. 14, No. 1, 13 November 2024.

<sup>35</sup> See https://eeebb0be-e8c8-4e71-9dcf-4514afffc587.usrfiles.com/ugd/eeebb0\_332d92c2e248466183d9ffffc8be6d07.pdf.

<sup>36</sup> See Sarah Khan, Rudransh Mukherjee and Joyojeet Pal, "Influencer collaboration on YouTube: changing political outreach in the 2024 Indian Elections", research paper, University of Michigan, 28 January 2024.

24. Acknowledging the increasing impact of influencers, the Council of the European Union has issued recommendations to the European Commission and member States to strengthen the legal and social responsibility of influencers in the digital media landscape.<sup>38</sup> Overall, however, influencers are free to disseminate polarizing and partisan narratives.

25. Although interference from generative artificial intelligence in the 2024 elections did not materialize to the extent anticipated, it is an emerging concern. The impact of generative artificial intelligence cannot be generalized, as differences in digitalization around the world mean that their effects on political life vary between countries. Any assessment of risks, effects and mitigation strategies should be tailored to local contexts.

26. As artificial intelligence tools become more accessible, scalable and sophisticated, their benefits and risks are becoming more visible.<sup>39</sup> They can enhance political campaign outreach and enable customized messaging or create deceptive content and amplify disinformation. An emerging use of artificial intelligence in elections is as a tool to boost the speed and accuracy of fact-checking. In parallel, the use of artificial intelligence as the basis for platform content curation is affecting the formation of opinions in disturbing ways that are not fully understood. The non-consensual manipulation of thinking processes contravenes the absolute right to freedom of opinion.<sup>40</sup>

27. The impact of artificial intelligence tools on the right to freedom of opinion and expression in electoral contexts could have deep consequences for democracy and deserves more scrutiny.<sup>41</sup> The Special Rapporteur intends to cover the issue more thoroughly in the future.

# **C. Media freedom in decline**

28. Free, independent, diverse and pluralistic media online and offline is a critical source of information and an antidote to disinformation.<sup>42</sup> It plays a vital role as a watchdog and fact checker in elections. Furthermore, despite the growth of social media, legacy media remains the main source of news for the third of the world's population with no access to the Internet.

29. The decline of media freedom is a serious setback for the electoral information environment. Three factors deserve urgent attention: attacks on journalists; the erosion of media independence, pluralism and financial viability; and the growing public distrust of the media.

30. Violence against journalists by State or non-State actors, such as political cadres, is a common feature of elections in almost all regions of the world. It endangers independent reporting and can lead to self-censorship. For instance, in Georgia, 75 journalists were physically attacked in 29 incidents, some at polling stations, while covering parliamentary elections.<sup>43</sup> The 2024 elections in Mozambique were marred by extreme levels of violence, including intimidation and attacks on journalists.<sup>44</sup> Women journalists face heightened risks of physical and gender-based violence and online attacks during elections.

31. Some political leaders, including incumbents, have attacked independent media harshly as fake news, seeking to discredit critical journalists and expose them to public hostility, harassment and violence.<sup>45</sup> Often, well-orchestrated campaigns are launched by vested political interests to undermine the credibility of independent media outlets and journalists who speak truth to power. Journalists and media outlets are attacked on social media as liars, traitors or foreign agents. Increasingly, legal systems are being weaponized to harass and intimidate journalists with vexatious claims.

<sup>37</sup> See Christina Peter and Luisa Muth, "Social media influencers' role in shaping political opinions and actions of young audiences", *Media and Communication*, vol.11, No. 3, June 2023.

<sup>38</sup> See Council of the European Union, "Council conclusions on support for influencers as online content creators", document 9301/24, 14 May 2024.

<sup>39</sup> See submission from Center for Democracy and Technology.

<sup>40</sup> [A/HRC/47/25,](https://docs.un.org/en/A/HRC/47/25) para. 36.

<sup>41</sup> See https://www.ohchr.org/sites/default/files/documents/issues/expression/activities/20250507-jointstm-ai-freedex.pdf.

<sup>42</sup> [A/HRC/47/25,](https://docs.un.org/en/A/HRC/47/25) para. 23.

<sup>43</sup> See https://www.ecpmf.eu/wp-content/uploads/2025/02/Monitoring-Report-2024.pdf, p. 23.

<sup>44</sup> See communication MOZ 2/2024.

32. Media independence, pluralism and economic viability are also in decline, adding to the public distrust of the media. In some countries, independent media is effectively non-existent because an authoritarian State exerts total media control. In others, the media has been captured by political actors, wealthy donors or business entrepreneurs aligned with the State or other powerful interests.

33. The relationship between the news media and so-called big tech is increasingly shaped by media dependencies, including content visibility, discoverability, prioritization and information bubbles, which reduce media diversity and pluralism.<sup>46</sup> As readers and audiences shift to digital platforms, the resulting business and financial problems of the media outlets make them more vulnerable to closure or capture.<sup>47</sup> State-controlled, captured or heavily partisan news media often acts as a conduit for misinformation and disinformation, further undermining public trust.<sup>48</sup>

34. The concentration of media ownership has long been acknowledged as a major threat to media pluralism. During elections, it can lead to heavily partisan coverage that undercuts public trust in credible journalism and encourages divisive political debate. That has occurred in the United States, where a handful of firms own over 600 licensed commercial broadcast stations. Increasing consolidation has been accompanied by diminished objectivity and rising polarization.<sup>49</sup>

# **III. Responsibilities and responses of States**

35. States and digital technology companies are key stakeholders during elections. The present chapter contains an examination of the policies and practices of States and their international legal obligations regarding freedom of expression and public participation.

### **A. International legal framework**

36. The right to freedom of opinion and expression and the right to public participation, including the right to vote, are interdependent. As noted by the Human Rights Committee, citizens take part in the conduct of public affairs by exerting influence through public debate and dialogue with their representatives, and their participation is supported by ensuring freedom of expression, assembly and association.<sup>50</sup>

37. Under article 25 of the International Covenant on Civil and Political Rights, citizens have the right to take part in the conduct of public affairs, directly or through freely chosen representatives and to vote and to be elected at genuine periodic elections which should be held by secret ballot, guaranteeing the free expression of the will of the electors. States have positive obligations to create the necessary conditions for the exercise of that right.

38. States have a duty to protect the right of all citizens, including those who are particularly at risk, such as political opponents, minorities, migrants, journalists and human rights defenders, to participate effectively and safely in political life. Those obligations are binding on all branches of the State and on all public or governmental authorities, including electoral management bodies (election commissions) and incumbent politicians.<sup>51</sup>

<sup>45</sup> See "Joint statement of United Nations experts on strengthening democracy and human rights in a year of worldwide elections", 30 April 2024.

<sup>46</sup> See submission from OSCE.

<sup>47</sup> [A/HRC/50/29,](https://docs.un.org/en/A/HRC/50/29) para. 86.

<sup>48</sup> [A/HRC/56/53/Add.2,](https://docs.un.org/en/A/HRC/56/53/Add.2) para. 24.

<sup>49</sup> See Mary R. Hornak, "Media consolidation and political polarization: reviewing the national television ownership rule", *Fordham Law Review*, vol. 90, No. 2 (2021).

<sup>50</sup> Human Rights Committee, general comment No. 25 (1996) on participation in public affairs and the right to vote, para. 8.

39. The Human Rights Committee has acknowledged freedom of expression as a necessary condition for the realization of the right to public participation.<sup>52</sup> Paragraph 19 (2) of the Covenant provides that freedom of expression encompasses the freedom to seek, receive and impart information and ideas of all kinds regardless of frontiers or types of media, either offline or online. The right to freedom of expression places upon States a positive obligation to provide easy, prompt, effective and practical access to information held by public bodies, including entities carrying out public functions, such as electoral commissions, and includes the right of the media to have access to information on public affairs as well as a right of the public to receive media output.<sup>53</sup>

40. Freedom of expression may be restricted only in accordance with article 19 (3) of Covenant, under which the restriction must be provided by law and be necessary for the legitimate aim of respecting the rights and reputations of others or for protecting national security, public order, public health or public morals. The principle of legality means that the scope, meaning and effect of the law must be clear, precise and public. Vague laws that confer excessive discretion can lead to arbitrary decision-making and are incompatible with article 19 (3). The principle of necessity requires the restriction to be appropriate and proportionate to achieve one of the legitimate aims. The directness of the causal relationship between the speech and the harm and the severity and immediacy of the harm are key considerations in assessing whether the restriction is necessary and proportionate.

41. Disinformation and hate speech are serious threats to freedom of expression and public participation, especially during elections. The Human Rights Council has affirmed that all responses by States to address disinformation must be grounded in international human rights law. <sup>54</sup> The restriction of speech to combat disinformation must meet the standards set out in article 19 (3). Falsehood alone is not sufficient to restrict speech in the absence of harm.

42. While international law does not use the term "hate speech", under article 20 (2) of the Covenant, States must prohibit by law the advocacy of national, racial or religious hatred that constitutes incitement to discrimination, hostility or violence. Incitement to discrimination, hostility or violence on the grounds of race is also prohibited by the International Convention on the Elimination of All Forms of Racial Discrimination (art. 4 (a)).

43. Criminal sanctions punishing acts of expression constitute a serious interference in the right to freedom of expression and should be used only in the most serious cases.<sup>55</sup> The need to restrict, prohibit or criminalize statements that could cause harm must be balanced against the right to express one's views freely during elections and the likelihood of abuse of the criminal law by States in the highly politicized environment of elections. The Rabat Plan of Action on the prohibition of advocacy of national, racial or religious hatred that constitutes incitement to discrimination, hostility or violence provides valuable guidance for achieving that balance through contextualization.

### **B. Responses of States**

44. While some States promote freedom of expression and good electoral practices, others have sought to disrupt access to information, suppress political expression and undermine media freedom.

<sup>51</sup> Human Rights Committee, general comment No. 34 (2011) on the freedoms of opinion and expression, para. 7.

<sup>52</sup> Ibid., para. 20; and Human Rights Committee, general comment No. 25 (1996), para. 8.

<sup>53</sup> Human Rights Committee, general comment No. 34 (2011), paras. 18 and 19.

<sup>54</sup> See Human Rights Council resolution 49/21 and General Assembly resolution 76/227.

<sup>55</sup> Human Rights Committee, general comment No. 34 (2011), para. 47.

### **1. Good practices**

#### **(a) Fulfilling the right to information**

45. Access to timely and accurate information gains heightened significance in the context of elections. Governments have taken a wide range of measures, typically through electoral management bodies (election commissions), to fulfil the right to information regarding elections for all citizens and the media. For example, the election commissions of Austria and Spain adopted various measures to facilitate access to information by citizens living with disabilities.<sup>56</sup> With a view to reducing the digital divide, the National Electoral Institute of Mexico adopted specific electoral information strategies for rural and Indigenous communities and other vulnerable groups. <sup>57</sup> The election commission of Ireland offers capacity-building and guidance to local authorities, developed in consultation with regional organizations.<sup>58</sup> The National Electoral Chamber of Argentina launched a chatbot service with the support of Meta to provide up-to-date and instantly accessible electoral information.<sup>59</sup>

### **(b) Fighting disinformation**

46. Several election commissions counter electoral disinformation with timely and reliable information. The election commission of the United Kingdom of Great Britain and Northern Ireland responds directly to social media posts containing false information about electoral procedures. <sup>60</sup> The election commission of Australia maintains a disinformation register, which was reportedly used effectively during the 2023 Voice Referendum campaign.<sup>61</sup>

47. In a positive model of State and civil society partnership to tackle disinformation while respecting human rights, the electoral commission of South Africa and the nongovernmental organization Media Monitoring Africa established a portal for the public to report online harms and a group of independent experts to assess the complaints and advise on further action. The platform provides transparency and accountability through a publicly accessible archive of complaints and an appeal system.<sup>62</sup>

#### **(c) Regulation**

48. The European Union Digital Services Act is a promising example of smart regulation, despite some limitations.<sup>63</sup> It embodies a risk-based approach to regulation focused not on content but on the enforcement of due diligence. Ahead of the 2024 European Parliament elections, the European Commission identified measures that social media platforms and search engines should adopt under the Act to increase transparency and mitigate electoral risks and launched proceedings to investigate several large platforms suspected of failing to comply. Following the annulment of the presidential election in Romania by its national courts in December 2024 over concerns of foreign manipulation facilitated by TikTok, the European Commission opened proceedings against the platform.<sup>64</sup> The outcome of that case will test the effectiveness of the Act.

<sup>56</sup> See submissions from Austria and Spain.

<sup>57</sup> See submission from Mexico.

<sup>58</sup> See submission from Ireland.

<sup>59</sup> See Turn.io, "Argentina's National Electoral Chamber 'Vot-A' chatbot: a trusted resource ahead of 2023 presidential polls", 9 October 2023.

<sup>60</sup> See submission from the United Kingdom.

<sup>61</sup> See submission from Maria O'Sullivan.

<sup>62</sup> See submission from Media Monitoring Africa.

<sup>63</sup> See submission from Centro de Estudios en Libertad de Expresión y Acceso a la Información.

<sup>64</sup> See European Digital Media Observatory, "Analysis of the 2024 Romanian presidential elections: the role of social media and emerging political trends", 26 November 2024.

#### **2. Concerns and challenges**

#### **(a) Online censorship**

49. Blanket Internet shutdowns are an inherently disproportionate and unlawful restriction of the right to information.<sup>65</sup> The number of election-related shutdowns jumped from 5 in 2023 to 12 in 2024.<sup>66</sup>

50. Governments that resort to Internet shutdowns often claim that they are aimed at preventing the spread of disinformation or foreign interference in elections. In reality, shutdowns disrupt the public's access to electoral information, the news media and communications from opposition candidates.

51. Through legal measures or in response to indirect requests and political pressure, many States regularly block websites or demand that social media platforms block individual accounts or take down posts, claiming that they contain false or misleading content. Such requests are particularly problematic during elections, as they lack transparency and independent oversight and are often aimed at restricting expression critical of the Government.

52. Officials in Cambodia ordered Internet service providers to block independent news websites a week before the July 2023 elections. <sup>67</sup> Just before the 2024 elections in the Bolivarian Republic of Venezuela, at least 53 digital media outlets were blocked and 14 radio stations closed.<sup>68</sup> In Mauritius, all social media platforms were blocked for 10 days prior to the 2024 election.<sup>69</sup> In Uganda, the blocking of Facebook imposed during the 2021 elections remained ongoing as of early 2025.<sup>70</sup> In India, the websites of platforms documenting hate crimes against marginalized communities were reportedly blocked by the authorities with no prior notice or recourse. <sup>71</sup> Leading up to the 2024 elections, the Government of India reportedly ordered Facebook, X and Instagram to block hundreds of accounts of activists.<sup>72</sup> As X users began migrating to Bluesky, Pakistan is reported to have extended a ban to that platform in addition to X.<sup>73</sup>

53. Social media guidelines set by the Brazilian judiciary after the 2022 election, while helping to contain anti-democratic elements, raised concerns within civil society about overreach, including regarding the forced removal of numerous posts and the blocking of social media profiles ex officio and confidentially by the electoral court.<sup>74</sup>

#### **(b) State-sponsored disinformation**

54. When States promote false narratives, they undermine their obligation to fulfil the right to information. State-sponsored disinformation can emanate from State institutions directly or through proxies. New technologies and new vectors, such as online influencers, have expanded significantly the scale, speed, spread and impact of State-sponsored disinformation directly and indirectly during elections.

55. In 2024, in at least 21 countries, government agents and pro-government commentators spread false or misleading narratives to undermine people's trust in the electoral system, manipulate online discussions or drown out reliable information.<sup>75</sup> In most cases, the purpose of the disinformation was to create legitimacy for elections that were not free or fair or to undermine the political opposition.

<sup>65</sup> See General Assembly resolution 57/29.

<sup>66</sup> See submission from Access Now.

<sup>67</sup> See submission from Freedom House.

<sup>68</sup> See communication VEN 7/2024.

<sup>69</sup> See Access Now and #KeepItOn coalition, "Emboldened offenders, endangered communities: Internet shutdowns in 2024", 24 February 2025.

<sup>70</sup> Ibid.

<sup>71</sup> See submission from Internet Freedom Foundation.

<sup>72</sup> See submission from Article 19.

<sup>73</sup> See Rezwan, "A year of elections and digital repression in South Asia: 2024 in focus", Global Voices, 2 January 2025.

<sup>74</sup> See submission from Conectas Direitos Humanos and Article 19: International Centre against Censorship (Brazil and South America).

<sup>75</sup> See submission from Freedom House.

56. In the lead-up to the European Parliament elections in June 2024, influencers supporting the ruling party of Hungary published videos characterizing the political opposition and independent news outlets as being controlled by foreign donors.<sup>76</sup> The 2023 elections in Serbia were marred by what some called government-driven "information chaos". <sup>77</sup> In Belarus, State television attacked the exiled opposition as "terrorists" or "extremists".<sup>78</sup> A think-tank of exiled Russian researchers reported that the social media platforms VKontakte and Telegram featured at least 100,000 public organizations and thousands of public sector employees pushing State propaganda in support of incumbents in Russian elections.<sup>79</sup>

#### **(c) Attacks on fact checkers**

57. Independent fact checkers and independent media are vital resources for countering false narratives. Both have come under attack during elections.

58. Fact-checking organizations have been smeared or investigated in many countries, often with chilling effect. In South Korea, a leading fact-checking centre scaled down its activities after being smeared by the ruling party.<sup>80</sup> In Egypt, on election day in 2023, the media authority launched an investigation into a platform reporting on the suppression of electoral information. <sup>81</sup> In the United States, legal harassment and smear campaigns by governmental and non-governmental actors reportedly led the Stanford Internet Observatory and the Election Integrity Partnership to discontinue their work during the 2024 elections.<sup>82</sup>

59. On the positive side, civil society has rallied to boost independent fact-checking. In India, the Shakti Collective, a consortium of more than 50 fact-checking groups and media organizations, worked to identify disinformation and artificial intelligence-generated content and translate fact-checked information into the many languages of India.<sup>83</sup>

#### **(d) Criminalization of expression**

60. States have historically used criminal law as a weapon to silence dissent.<sup>84</sup> Because of the inherent abuse of criminal libel to suppress criticism of State policies and officials, the Special Rapporteur has repeatedly called for the decriminalization of libel.<sup>85</sup>

61. In recent years, cyberlibel and cybercrime laws have been adopted to criminalize expression online. Another alarming trend has been the proliferation of fake news laws aimed at criminalizing legitimate online expression under the guise of combating disinformation. Most fake news, criminal libel, cyberlibel and cybercrime laws fail to meet the standards of legality, necessity and proportionality set out in the International Covenant on Civil and Political Rights.

62. Tunisia has used its cybercrime law to prosecute and imprison candidates, journalists, lawyers, judges and human rights defenders. During the 2022 parliamentary elections in Lebanon, over two thirds of social media posts sanctioned by the electoral authorities were sanctioned on defamation grounds, with some individuals forced to sign pledges not to criticize officials.<sup>86</sup> In Bangladesh, the Digital Security Act and its successor legislation were used to harass, detain and prosecute hundreds of journalists, human rights defenders and political opponents, chilling media reporting and political participation in successive elections.<sup>87</sup> The interim Government of Bangladesh has promised to reform the law ahead of the upcoming elections.

<sup>76</sup> See submission from Hungarian Helsinki Committee.

<sup>77</sup> See Mila Bajić and Grant Baker, "'Information chaos' plagues Serbia elections", Center for European Policy Analysis, 15 December 2023; and European Parliament, "Serbia did not fulfil its commitments to free and fair elections, say MEPs", 8 February 2024.

<sup>78</sup> See submission from Respect-Protect-Fulfill.

<sup>79</sup> See Center for Data and Research on Russia, "Social media monitoring on the eve of the presidential elections in Russia", March 2024, available at https://cedarus.io/research/elections-monitoring.

<sup>80</sup> See submission from Freedom House.

<sup>81</sup> Ibid.

<sup>82</sup> See submission from Center for Democracy and Technology.

<sup>83</sup> See submission from Freedom House.

<sup>84</sup> [A/HRC/26/30,](https://docs.un.org/en/A/HRC/26/30) paras. 38 and 39.

<sup>85</sup> [A/HRC/50/29,](https://docs.un.org/en/A/HRC/50/29) paras. 57 and 58. See also [A/HRC/47/25,](https://docs.un.org/en/A/HRC/47/25) para. 52.

63. The combined effect of repressive measures can be severe. During the May 2023 elections in Türkiye, independent observers found that criminal laws on defamation, insult and the dissemination of "false" information, the blocking of websites, content takedown requests and the detention and prosecution of journalists had a severe chilling effect on freedom of expression.<sup>88</sup>

#### **(e) Weak electoral management bodies**

64. As State organs, electoral commissions should proactively provide accurate and timely information on the electoral process and election results. They should also be able to debunk rapidly and accurately false information on electoral issues.

65. Many electoral bodies are unable to play their role effectively due to a lack of capacity, expertise, resources and institutional independence or because of undue political influence. In Sri Lanka, the Election Commission allegedly cited loopholes in the Right to Information Act to keep electoral information confidential,<sup>89</sup> aggravating public distrust in the electoral process.

66. Furthermore, many electoral commissions struggle with emerging digital challenges, such as the use of generative artificial intelligence or the role of online influencers.

# **IV. Companies: responsibilities and responses**

67. While companies do not have the same human rights obligations as States, they are expected to respect human rights in their operations and activities in line with the Guiding Principles on Business and Human Rights. At a minimum they should conduct due diligence with a view to identifying, preventing and mitigating any potential or actual adverse impact of their policies, products and operations on human rights, conduct regular human rights impact assessments and put in place a remediation process for users.

#### **A. Specific responses to elections**

68. Social media platforms and search engines play a crucial role in the electoral information environment. They enhance access to information and enable broader political engagement. They also amplify harmful speech, however, and overly restrict lawful content. Companies have developed automated, human and expert-driven processes to safeguard platforms from information manipulation during elections. Their effectiveness has been varied, and recent moves to roll back key policies and programmes without due diligence or stakeholder consultation raise considerable concerns.

69. Some platforms took specific steps to address electoral information challenges in 2024. Meta ran several election operations around the world to monitor content, update policies and react swiftly in specific countries.<sup>90</sup> Prior to the European Parliament elections in 2024 and the national elections in Germany in 2025, the large platforms worked with national digital services authorities to conduct simulations of election risks or stress tests.<sup>91</sup> Platforms also monitored foreign influence operations.

<sup>86</sup> See European Union Election Observation Mission, *Lebanon 2022, Parliamentary Elections, 15 May 2022*, Final Report.

<sup>87</sup> See communications BGD 2/2023 and BGD 7/2023.

<sup>88</sup> See Office for Democratic Institutions and Human Rights Election Observation Mission, *Republic of Türkiye: General Elections 14 May and Presidential Election, Second Round 28 May* 2023, Final Report (Warsaw, OSCE, 2023).

<sup>89</sup> See submission from Asian Forum for Human Rights and Development.

<sup>90</sup> See Nick Clegg, "What we saw on our platforms during 2024's global elections", Meta, 3 December 2024.

70. Acknowledging the potential risks of generative artificial intelligence in elections, major platforms devoted resources to identifying, publishing reports and addressing the harmful impacts of artificial intelligence-driven technologies, such as deepfakes and bot networks.<sup>92</sup> Dozens of leading companies, including Meta, signed an industry-led accord to address the use of deceptive artificial intelligence in 2024.<sup>93</sup>

### **B. Concerns and challenges**

#### **1. Rollback by platforms**

71. There is deep concern that, at a time of rising hate and lies, the large platforms are backsliding on their commitments to electoral integrity, safety, transparency and risk management. Since 2022, the largest platforms have radically scaled down staff and resources and rolled back key policies, while simultaneously expanding their investment in artificial intelligence tools, including for recommenders and ranking systems. <sup>94</sup> The retrenchments have been heaviest at Meta, X and Google and have hit hardest at the trust and safety teams.<sup>95</sup>

72. Although economic considerations and the rise of generative artificial intelligence have been the key factors influencing staff cuts, political and ideological considerations have also figured prominently. Under the leadership of Elon Musk, X has retreated totally from content moderation and user safety in the name of promoting "free speech". YouTube has rolled back policies designed to limit "big lie" content questioning the results of the 2020 elections in the United States.<sup>96</sup> Meta has scaled back its moderation of harmful speech, leading the Meta Safety Advisory Council, an independent body of experts, to observe that the company risked prioritizing political ideologies over global safety imperatives.<sup>97</sup>

73. In early 2025, Meta abruptly decided to stop working with professional fact checkers and moved to a "community notes" style of moderation, similar to that used by X, despite concerns about its efficacy.<sup>98</sup> While Meta's decision was aimed at the American market, factchecking initiatives involve local partners all over the world. Stakeholders across Africa are concerned that Meta's move will diminish the chances for greater platform accountability across the continent.<sup>99</sup> The move also appears to contradict Meta's significant past support to improving the skills and capabilities of European fact checkers.

74. Meta's Oversight Board noted that the company had failed to follow its own policy of conducting human rights due diligence prior to making significant changes. The Board called upon Meta to live up to its public commitment to uphold the Guiding Principles on Business and Human Rights and to identify and address adverse impacts on human rights resulting

<sup>91</sup> See European Commission, "German Digital Services Coordinator tests platforms' readiness under the Digital Services Act", 31 January 2025.

<sup>92</sup> See https://transparency.meta.com/metasecurity/threat-reporting; and https://www.tiktok.com/transparency/en-us/countering-influence-operations.

<sup>93</sup> See International Republican Institute, "Democracy in the age of generative AI: navigating risks and harnessing opportunities", white paper (2024), available at https://www.iri.org/wpcontent/uploads/2024/08/GenAI-Democracy-White-Paper-Final.pdf.

<sup>94</sup> See Paul M. Barrett, Cecely Richard-Carvajal and Justin Hendrix, *Digital Risks to the 2024 Elections*: *Safeguarding Democracy in an Era of Disinformation*, NYU Stern Center for Business and Human Rights (2024).

<sup>95</sup> See Nora Benavidez, "Big tech backslide: how social-media rollbacks endanger democracy ahead of the 2024 elections", Free Press, December 2023, available at

https://www.freepress.net/sites/default/files/2023-12/free\_press\_report\_big\_tech\_backslide.pdf. <sup>96</sup> Ibid., p. 9.

<sup>97</sup> See https://assets.projectrockit.com.au/assets/Safety-Advisory-Council-%E2%80%93-Letter-to-Meta.pdf.

<sup>98</sup> See submission from Derechos Digitales, Tecnología y Communidad, Instituto Panamericano de Derecho y Tenología and Karisma Foundation.

<sup>99</sup> See submission from Association for Progressive Communications.

from the changes, including assessing whether reducing its reliance on the automated detection of policy violations could have uneven consequences globally.<sup>100</sup>

75. There is fear of more backsliding by platforms, given the current political climate in the United States, as exemplified in a recent executive order signed by the President announcing the end of the "federal censorship" of online platforms.<sup>101</sup>

#### **2. Amplification of harmful content**

76. The business model of online platforms incentivizes the amplification of harmful and illegal content, such as hate speech and disinformation. The monetization structures of platforms continue to facilitate and amplify harmful content and disinformation in recommender systems, including through electoral political advertisements that contravene stated platform policies.<sup>102</sup> Online political advertisers spent \$1.35 billion on Google and Meta during the 2024 election cycle in the United States.<sup>103</sup> Approaches by platforms to defining "political advertisements" vary wildly, heavily affecting the extent to which they are transparent in their advertising practices and in requiring "paid for" disclosures.<sup>104</sup>

77. Curation algorithms often disproportionately amplify extreme viewpoints. For instance, in the lead-up to the 2025 elections in Germany, one report found that 78 per cent of recommended political content on TikTok and 64 per cent on X was supportive of the farright Alternative für Deutschland party, despite the party trailing at less than a quarter in the polls.<sup>105</sup>

78. While platforms need to do more to keep elections safe, effective regulation and strong oversight can spur them to action. A case in point is TikTok, which was implicated in the alleged foreign interference in the December 2024 elections in Romania and is under investigation by the European Commission. Although the Commission has not yet completed its investigation, the platform took various measures ahead of the country's rerun elections in May 2025, including hiring Romanian language experts and specialists on covert influence and strengthening the detection and labelling of political accounts.

79. The accounts of high-profile public figures deserve greater protection but also greater scrutiny and quicker escalation to human review if there are indications that they are likely to instigate harm. Harmful content, whether in political advertisements or political comments, can lead to imminent, real-world violence. During the highly polarized elections in Brazil in 2022, the Oversight Board admonished Facebook's failure to moderate the postings of a Brazilian general, which may have contributed to incitement to violence.<sup>106</sup> Despite real and imminent risks of offline harm during a period of government crackdown on the political opposition in Cambodia, Meta rejected the Oversight Board's guidance to temporarily close down the account of the country's prime minister, who continued to threaten opponents with violence.<sup>107</sup>

80. In spite of promises to act equitably across all regions, the protection measures of platforms continue to be uneven or non-existent in certain languages and regions. For instance, despite heightened tensions in the Middle East, neither Meta, Google nor X appear to have implemented safeguards for the September 2024 ballots in Jordan or sufficiently

<sup>100</sup> See https://www.oversightboard.com/news/wide-ranging-decisions-protect-speech-and-addressharms.

<sup>101</sup> See https://www.whitehouse.gov/presidential-actions/2025/01/restoring-freedom-of-speech-andending-federal-censorship.

<sup>102</sup> See Max Read and Jessica Mahoney, "Social media platforms fall short on enforcing ads policies", Institute for Strategic Dialogue, 31 October 2024.

<sup>103</sup> See https://www.brennancenter.org/our-work/analysis-opinion/online-ad-spending-2024-electiontopped-135-billion.

<sup>104</sup> See Laura Kurek and others, "Rules of the road: political advertising on social media in the 2024 U.S. election", Center for Democracy and Technology, September 2024.

<sup>105</sup> See Global Witness, "X and TikTok algorithms push pro-AfD content to non-partisan German users: new analysis", 20 February 2025.

<sup>106</sup> See https://www.oversightboard.com/decision/fb-659eawi8.

<sup>107</sup> See https://www.oversightboard.com/decision/fb-6okjpns3; and Reuters, "Meta rejects recommendation to suspend former Cambodia PM from Facebook", 30 August 2023.

invested in Arabic-speaking content experts.<sup>108</sup> Although Facebook and Google have offices in Colombia, non-governmental organizations reported that no specific actions had been taken to mitigate online hate speech and information manipulation in recent elections.<sup>109</sup>

81. The growing shift from traditional media to live broadcasts on social media platforms has brought additional challenges. An independent human rights impact assessment of the Amazon-owned Twitch, which generated more viewership in the 2024 elections in the United States than major news organizations, found that the use of live video in the electoral context posed significant threats with regard to disinformation, hate speech and offline violence.<sup>110</sup> Platforms need to devote more resources to developing appropriate systems for responding to disinformation or incitement when the harm occurs in real time with little margin for moderation.

#### **3. Over-moderation of political content**

82. Two major causes of restriction of political content online are government requests to platforms to remove content and disproportionate content moderation by platforms.

83. Takedown requests from Governments tend to target political opponents, independent media and human rights defenders. Platforms often accede to the requests because refusal can lead to severe legal and other consequences for the platforms but when platforms accept demands that do not align with international standards of freedom of expression they are, in effect, complicit in censorship. While they may be subject to local laws, the platforms are, nevertheless, obliged to assess the impact of their decisions in the light of their human rights responsibilities and to take steps to mitigate that impact to the extent possible. At a minimum, platforms should adopt globally consistent policies on takedown decisions and make such requests and their responses public. Meta and X publicized their decisions to take down posts in response to demands from the authorities ahead of elections in Indonesia<sup>111</sup> and Türkiye.<sup>112</sup>

84. Most content moderation decisions are made by machines, not human beings, and that is one reason for the excessive removal of content. Automated systems struggle with the nuances and context of political expression, particularly in highly sensitive situations during elections and when dealing with minorities or posts in non-English languages. There have been complaints, for instance, that while gender-based violence against Black and Asian-American women is overlooked, speech by the same groups is over-moderated. <sup>113</sup>

85. There are concerns that companies do not invest sufficiently in elections in countries or markets that are not commercially lucrative. Consistent and well-resourced staffing is important in terms of both locally relevant languages and contextual knowledge and technical expertise.

86. As platforms roll back content moderation policies, including those relating to elections in the United States, there is growing concern that ideological and political considerations may be creeping into content moderation. Meta's sudden policy changes in early 2025 led one expert to describe it as the open political capture of Facebook and its pandering to a particular party.<sup>114</sup>

#### **4. Transparency and access to researchers**

87. Transparency is key to accountability. Civil society organizations and experts continue to be concerned about the adequacy of platforms' transparency measures, including notice to users regarding moderation, reasons for takedowns, policies and practices surrounding elections and information on human rights impact assessments. Some

<sup>108</sup> See Digital Action, "Jordan country briefing", 9 October 2024.

<sup>109</sup> See submission from El Veinte.

<sup>110</sup> Business for Social Responsibility, *Twitch Human Rights Impact Assessment*, April 2023, p. 16.

<sup>111</sup> See submission from Commission for the Disappeared and Victims of Violence and Southeast Asia Freedom of Expression Network.

<sup>112</sup> See submission from Article 19: International Centre against Censorship.

<sup>113</sup> See submission from Center for Digital Technology.

<sup>114</sup> See Sam Biddle, "Leaked Meta rules: users are free to post 'Mexican immigrants are trash!' or 'trans people are immoral'", *The Intercept*, 9 January 2025.

researchers have claimed that their current visibility into Meta's content moderation, including its role in the 2024 elections, is "near zero."<sup>115</sup>

88. Transparency measures are often discretionary and inconsistent. During elections in 2024, many electoral management bodies worldwide reported positive partnerships with major platforms. There were also reports of stonewalling by platforms, however, when electoral bodies sought records relating to risk assessments and the application of election policies, even when requests were made under access-to-information laws. Google, X and Meta reportedly resisted such data requests from the Electoral Commission of South Africa.<sup>116</sup>

89. Granting researchers access to platform data allows independent research to inform effective policies and technical interventions. Yet such access continues to be curtailed, made too expensive or offered in formats that are not useful for research. Even where data is available, there can be significant inconsistencies in content and format, making research and comparison difficult.

90. In 2024, Meta deactivated CrowdTangle, a tool that was critical for researchers studying political interactions on the platform, and replaced it with the Ad Library, which is more restrictive and effectively excludes journalists and independent researchers.<sup>117</sup> X has made it prohibitively expensive for researchers to obtain its data via application programming interfaces.<sup>118</sup> The Digital Services Act of the European Union provides a mechanism through which independent researchers can exercise their right to obtain data from large platforms but that aspect of the Act has yet to be operationalized.

# **V. Conclusions and recommendations**

91. **Polarized politics, rising authoritarian trends, backsliding platforms awash in hate speech and disinformation and a media sector too weak to debunk the lies have coalesced into a perfect storm in which freedom of expression and the right to vote are imperilled. Public trust in the integrity of elections and information is at an all-time low.**

92. **Lies, exaggeration and propaganda during elections are not new. The game changers are digital technology and social media platforms, which are enabling and amplifying the degradation of the electoral information environment and impeding the equal participation of citizens.**

93. **From that situation, the Special Rapporteur draws seven key conclusions:**

(a) **Firstly, elections are information crisis points in which access to accurate and timely information is vital but also highly vulnerable to attack, censorship and distortion. It is imperative that States, companies and civil society work together to protect freedom of expression and close the trust deficit on electoral integrity;**

(b) **Secondly, politicians and public officials play a central role in shaping public debate and opinion. They bear a significant responsibility for the degradation of the information environment. They should not abuse their privileged position to undermine electoral integrity, incite violence, hostility and discrimination or attack the media and civil society. Instead, through ethical behaviour, they should enhance the quality of political discourse and build public trust in elections;**

(c) **Thirdly, the backsliding of social media platforms on commitments to human rights and electoral integrity rings an alarm bell that States and the international community ignore at their peril. As the principal vector of information in**

<sup>115</sup> See Sandra Gonzalez-Bailón and David Lazer, "The need to make content moderation transparent", *Tech Policy Press*, 11 December 2024.

<sup>116</sup> See Amber Sinha, "Platforms and election management bodies in 2024–25: a tale of dramatically mixed results", *Tech Policy Press*, 9 April 2025.

<sup>117</sup> See submission from Derechos Digitales, Tecnología y Communidad, Instituto Panamericano de Derecho y Tenología and Karisma Foundation.

<sup>118</sup> See Daniela Alvarado Rincón and Ognjan Denkovski, "Why we're suing Elon Musk's X for German election data", *EUobserver*, 27 February 2025.

**the digital age, the platforms serve a public good and should not deprioritize human safety and human rights for political and commercial interests. As global companies with universal human rights responsibilities, platforms should ensure that their policies and programmes are globally consistent, fair and aligned with their international obligations;**

(d) **Fourthly, the decline of media freedom, independence, diversity and pluralism deserves urgent action. Democracy needs a healthy legacy media alongside a trustworthy online environment to ensure a diverse and vibrant electoral information system;**

(e) **Fifthly, undermining freedom of expression in the name of fighting disinformation is short-sighted and counterproductive. Freedom of expression is vital to healthy democratic discourse. That does not mean that disinformation cannot be restricted lawfully but that such restrictions must scrupulously respect the principles of legality, necessity, proportionality and legitimate objectives, as set out in article 19 (3) of the International Covenant on Civil and Political Rights;**

(f) **Sixthly, the advocacy of hatred and incitement to violence that masquerades as political speech has no protection under international law. Powerful public figures must not be permitted to instrumentalize the virality of platforms to incite violence or silence critical voices with threats of violence;**

(g) **Finally, experience has shown that multifaceted, multi-stakeholder strategies grounded in human rights and combining a range of legal and non-legal measures are the most effective way to fight disinformation and other forms of information manipulation.**

#### **A. Recommendations to States**

94. **States should provide timely, accurate and relevant information to citizens and the media regarding electoral processes, including on voting procedures, the rights of the electorate and candidates and election results. Information should be available in all relevant languages and formats to ensure the access and participation of all citizens, including minorities, women, Indigenous communities and persons living with disabilities.**

95. **As State organs, electoral commissions have a duty to promote the right to information, safeguard freedom of expression and debunk false information regarding electoral processes and results. States should ensure that electoral commissions are adequately resourced and enjoy the necessary authority and autonomy to carry out their duties without political interference.**

96. **Electoral commissions should proactively monitor the information environment online and offline, promote voter education and media and digital literacy and support the free flow of reliable, high-quality information from diverse sources***.*

97. **The digital divide is a barrier to the right to information. States should promote diverse technological solutions to achieve universal, meaningful access to the Internet, paying particular attention to inequalities affecting women and marginalized communities and creating an enabling regulatory environment for small community networks.**

98. **States have a duty to ensure that companies respect human rights. Social media regulation should not be aimed at controlling content but should encourage companies to carry out human rights due diligence and impact assessments, align their curation and moderation policies with human rights standards and adhere to high standards of transparency and accountability.**

99. **States should refrain from Internet shutdowns, disruptions and the blocking of platforms or websites, as such actions are inherently disproportionate. States should not compel platforms to censor, remove or block content that is legitimate under international law.**

100. **States, State entities and public officials must refrain from electoral disinformation and attacks on election officials, fact checkers and the media.**

101. **States should refrain from restricting freedom of expression both online and offline, including for the purposes of combating disinformation, except in accordance with the requirements of legality, necessity, proportionality and legitimate objectives as set out in international law.**

102. **States are obliged to prohibit the advocacy of hatred that constitutes incitement to violence, hostility and discrimination, regardless of who espouses it. Criminal law should be used only in the most egregious cases.**

103. **Given the high risk of abuse of criminal law, especially in electoral contexts, States should consider decriminalizing libel and cyberlibel offences.**

104. **States, public officials and politicians must refrain from attacking and discrediting the media and should promote an environment that is conducive to media freedom, independence, pluralism and diversity and the safety of journalists. States must take steps proactively to protect journalists and media workers during elections, and promptly investigate all complaints and incidents of threats or violence against the media.**

105. **States should develop multifaceted, multi-stakeholder, human rights-based strategies to counter electoral disinformation. Beginning with the State's own responsibility to provide factual and timely information, such strategies should promote an independent, pluralistic and diverse media, independent fact-checking, the digital and media literacy of the electorate and collaboration with civil society and companies. Electoral commissions should play a leading role in such activities, including setting up accessible mechanisms for citizens to report harmful speech and other good practices.**

#### **B. Recommendations to political parties**

106. **Political parties should adopt and enforce codes of conduct that set minimum standards of behaviour and accountability for their candidates, officials, members and workers, encouraging respect for freedom of expression and prohibiting online or offline violence or incitement to violence, hatred and discrimination against women, vulnerable or marginalized groups, journalists, human rights defenders, electoral officials and election observers.**

107. **Candidates and parties must be transparent regarding their transactional relationships with social media influencers and refrain from utilizing influencers or other proxies as surrogates for harmful speech and disinformation or from resharing and promoting such content.**

#### **C. Recommendations to companies**

108. **Social media platforms should set basic global standards for elections in all jurisdictions and apply them consistently and fairly, dedicating sufficient resources, including human resources and language and contextual expertise, irrespective of their own commercial and political interests in that market.**

109. **Platforms should conduct heightened human rights due diligence and impact assessments of content moderation and curation policies ahead of elections and ensure that they invest sufficiently in local languages, contextual expertise and fact-checking resources, including human resources. As part of their due diligence, platforms should work with the relevant national authorities and civil society organizations to conduct stress tests ahead of elections.**

110. **Platforms must ensure that their content curation, moderation and takedown policies are aligned with international human rights standards, including criteria and standards for restricting and prohibiting speech.**

111. **Platforms should develop globally consistent policies regarding their responses to government requests for takedowns, assessing the human rights implications, and consider all options before acceding to the requests. Where the requests are aimed at suppressing speech that is lawful under international law, platforms should consider all legal means to resist or, failing that, apply the restriction as narrowly as possible. Platforms should publish the requests and their responses as a regular practice.**

112. **Platforms should react rapidly and effectively to instances of incitement to violence and develop clear and consistent policies, including for the rapid escalation of decision-making regarding the accounts of high-profile political figures, considering the importance of protecting political expression but also the heightened risk of harm.**

113. **Companies should resist government orders to shut down the Internet or restrict access to digital services and should use all legal channels to challenge requests that appear to violate international human right standards.**

114. **Platforms should set requirements for transparency by social media influencers to disclose paid or in-kind affiliations with candidates or campaigns and ensure that recommender systems do not monetize the dissemination of disinformation or harmful speech by influencers.**

115. **Platforms should review their recommender algorithms and monetization systems, ensuring that they promote access to accurate electoral information and do not disproportionately amplify extreme viewpoints or harmful and sensational content or users. Platforms should be transparent regarding the algorithms and safety efforts that they undertake surrounding elections.**

116. **Platforms should support independent fact-checking organizations in collaboration with civil society organizations, particularly those that are relevant to the local context of elections. Platforms that have rolled back independent fact-checking or plan to do so should conduct independent due diligence and impact assessments and publish the results.**

117. **Platforms should collaborate with civil society to develop rights-based approaches to respond to inauthentic artificial intelligence content, tailored to local contexts.**

118. **Platforms should provide access to researchers in line with industry best practices.**

119. **Platforms should adopt meaningful transparency measures to communicate their election integrity efforts and ensure that policies and information on human rights due diligence, recommender systems and requests and demands by Governments are provided in relevant non-English languages in addition to English.**

120. **Platforms should engage proactively with stakeholders, including electoral commissions, the media, civil society and the United Nations human rights system, including the special procedure mandate holders, on a regular basis and especially prior to major policy changes.**