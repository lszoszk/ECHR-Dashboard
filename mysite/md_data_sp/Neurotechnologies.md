![](_page_0_Picture_2.jpeg)

16 January 2025 English Original: Spanish

**Human Rights Council Fifty-eighth session** 24 February–4 April 2025 Agenda item 3 **Promotion and protection of all human rights, civil, political, economic, social and cultural rights, including the right to development**

# **Foundations and principles for the regulation of neurotechnologies and the processing of neurodata from the perspective of the right to privacy**

**Report of the Special Rapporteur on the right to privacy, Ana Brian Nougrères**

## *Summary*

The present report sets out the basis for the creation of a conceptual framework for regulating the use of neurotechnologies and the processing of neurodata, from the perspective of the right to privacy. In particular, the report deals with key definitions and establishes fundamental principles to guide regulation in this area, including the protection of human dignity, the safeguarding of mental privacy, the recognition of neurodata as highly sensitive personal data and the requirement of informed consent for the processing thereof. Emphasis is also placed on the inclusion of ethical values and the protection of human rights in the design and use of these technologies and on the application of the precautionary principle, demonstrated accountability, the secure handling of neurodata, non-discrimination and the effective protection of the rights of individuals in the processing of their neurodata. This approach seeks to establish a sound basis for ensuring that the regulation of neurotechnologies is consistent, ethical and designed to safeguard fundamental rights.

![](_page_0_Picture_9.jpeg)

# **I. Background on neurotechnologies and neurodata processing at the United Nations**

1. Neurotechnologies are defined as methods, tools or devices to record or change brain activity.<sup>1</sup> Rafael Yuste, a professor in the Department of Biology at Columbia University in New York and the director of the BRAIN Project, notes that:

Neurotechnologies are important because the brain is not just any organ of the body, it is the one that generates the entirety of human mental and cognitive activity. Our thoughts, perceptions, emotions, memories, even the subconscious. everything comes from the coordinated activity of the neural circuits within our brains. With neurotechnology, for the first time ever, we can access these neural circuits, record their activity and change it.<sup>2</sup>

2. The challenges and opportunities presented by neurotechnologies and the processing of neurodata have been addressed by various United Nations bodies in an increasing number of resolutions and documents highlighting the relevance of these technologies, the risks of their misuse and the importance of establishing regulatory frameworks to protect human rights in the context of neurotechnologies. The information below highlights the most relevant aspects of these materials with respect to the issues associated with privacy and the processing of personal data.

## **A. Human Rights Council resolution 51/3 on neurotechnology and human rights**

3. In resolution 51/3, the Human Rights Council highlighted, firstly, that neurotechnology allows the connecting of the human brain directly to digital networks through devices and procedures that may be used, among other things, to access, monitor and manipulate the neural system of the person. It also recognized that neurotechnology could be promising for human health and innovation, but that, at the same time, the continued development of some of its applications may pose a number of ethical, legal and societal questions that need to be addressed, including in human rights terms. Lastly, it noted that, in his 2021 report entitled "Our Common Agenda", the Secretary-General had stated that consideration should be given to updating or clarifying the application of human rights frameworks and standards to address frontier issues and prevent harms in the digital or technology spaces, including in neurotechnology.

4. In the resolution, the Human Rights Council:

(a) Requested the Human Rights Council Advisory Committee to prepare a study in an accessible format, including an easy-to-read version, on the impact, opportunities and challenges of neurotechnology with regard to the promotion and protection of all human rights, including recommendations on how human rights opportunities, challenges and gaps arising from neurotechnology could be addressed by the Council and its special procedures and subsidiary bodies in a coherent, holistic, inclusive and action-oriented manner, and to present the study to the Council at its fifty-seventh session;

(b) Also requested the Advisory Committee, when preparing the above-mentioned study, to seek the views and inputs from, and to take into account the relevant work already done by, stakeholders, including Member States, international and regional organizations, the Office of the United Nations High Commissioner for Human Rights, the special procedures of the Human Rights Council, the treaty bodies, other relevant United Nations agencies, funds and programmes within their respective mandates, national human rights institutions, civil society, the private sector, medical and technical communities, academic institutions and other relevant stakeholders;

<sup>1</sup> R. Yuste, "Un paso histórico", in *En defensa de los neuroderechos*, M. Sánchez, C. Colombara and N. Monti, eds. (Kamanau, 2024), p. 7.

<sup>2</sup> Ibid.

(c) Invited the United Nations High Commissioner for Human Rights, the treaty bodies and the special procedures of the Human Rights Council, within their respective mandates, to give due consideration to the impact of neurotechnology on the full enjoyment of all human rights and fundamental freedoms;

(d) Decided to remain seized of the matter.

## **B. Proposal for the updating of General Assembly resolution 45/95, entitled "Guidelines for the regulation of computerized personal data files"**

5. In her report,<sup>3</sup> the Special Rapporteur highlighted the following concepts.

6. Firstly, she noted that since 1990, new technological phenomena have arisen and advancements have been made that have transformed our society and are part of our daily lives. By way of example, she highlighted that neurotechnologies have led to detailed knowledge of the brain and information on the neural systems of individuals (highly sensitive data).

7. The proposal to update General Assembly resolution 45/95 included the following:

(a) In connection with the principle of non-discrimination and non-manipulation, it was pointed out, inter alia, that data likely to give rise to unlawful or arbitrary discrimination, in particular neural data, among others, should not be recorded or processed. The report also stated that processing of neural data, or neurodata, must not be used to manipulate or alter the freedom of thought and consciousness of an individual, making him or her dependent on a third party or altering his or her ideas, security or independence or his or her natural cerebral identity or neurocognitive integrity. Nor may such data be processed for purposes other than the promotion of health and the diagnosis, rehabilitation and alleviation of disease in the context of the right to health, or scientific research in the fields of biology, psychology and medicine aimed at alleviating suffering or improving health;

(b) Under the principle of enhanced protection for sensitive data, neurodata, or neural data, was identified as sensitive data that must be subject to special enhanced responsibility measures with regard to security, confidentiality, access and restrictions on circulation, in order to prevent such data from being accessed, improperly used, manipulated or destroyed.

## **C. Impact, opportunities and challenges of neurotechnology with regard to the promotion and protection of all human rights**

8. The report of the Human Rights Council Advisory Committee<sup>4</sup> concluded, inter alia, that:

(a) Neurotechnologies affect human rights in a unique manner. Connecting human brains directly to digital networks has significant ethical implications for values underlying the human rights system (dignity, privacy, autonomy and agency) and may offer tools to alter human essence;

(b) Integrating a human rights approach into all national and international policies is a priority.

9. In the light of the foregoing, it was recommended that discussions should continue on the suitability of creating a special procedure mandate on emerging technologies to provide guidance on how to ensure that neurotechnologies are developed and deployed in full respect of human rights.

<sup>3</sup> [A/79/173.](http://undocs.org/en/A/79/173)

<sup>4</sup> [A/HRC/57/61.](http://undocs.org/en/A/HRC/57/61)

10. In addition, it was recommended that Member States should:

(a) Exercise due diligence in regulating, monitoring and sanctioning the conduct of actors that develop, commercialize or require the use of neurotechnologies as a means to prevent the endangerment of the enjoyment of human rights and take measures to remedy their violation; develop a regulatory protective framework able to address the particularities of neurotechnologies, including existing and potential impacts on human rights; adopt measures to ensure that the national normative framework, including civil, criminal and labour laws, is adequate to deal with the new challenges posed by neurotechnologies, also by developing institutional mechanisms capable of anticipating and taking action to prevent human rights violations and abuses and consider reinforcing the competences of national human rights institutions to that end;

(b) Take an active role and promote a human rights-based approach in ongoing debates on the governance of neurotechnologies and related issues, such as artificial intelligence; consider the adoption of international instruments to establish a moratorium or prohibit the use of technologies, including in the military, law enforcement and criminal justice fields, that pose risks of misuse or abuse, including irreversible damage, leading to human rights violations;

(c) Ensure that persons with disabilities and other relevant groups, such as older persons, are granted access to human rights-compliant, safe and reliable neurotechnologies under non-discriminatory and affordable conditions and that their rights are effectively protected in practice from negative impacts and misuses in the development and implementation phases; and ensure access to neurotechnologies to persons who can benefit therefrom for health and medical purposes;

(d) Ensure that consent is always prior, free, informed, real, transparent and effective and never assumed in any neurointerventions; adopt measures to ensure that persons in vulnerable situations (i.e. persons with mental health conditions and psychosocial disabilities, defendants in criminal procedures and convicted offenders) are effectively protected from human rights violations, misuses and abuses, particularly from non-consensual medical treatment and experimentation.

# **II. Benefits and challenges of neurotechnologies**

11. According to Yuste, the benefits of the use of neurotechnologies include the following:

(a) Conducting research to discover how the brain works and understand the scientific basis of the human mind;

(b) Diagnosing, understanding and designing new therapies for neurological and neurodegenerative or psychiatric brain diseases such as, inter alia, Alzheimer's, schizophrenia, Parkinson's, epilepsy, mental impairment, stroke, lateral sclerosis, depression and anxiety. These brain diseases are increasingly affecting a large percentage of the population and are a blight on humanity;

(c) Encouraging the creation of brain-computer interface devices that connect directly to the Internet and establishing a new industry with great economic and consumer benefits.<sup>5</sup>

12. Nevertheless, neurotechnologies also give rise to risks, including the following:

(a) The use of neurotechnologies for purposes contrary to human dignity. With these technologies, brain activity can be decoded and altered, which gives rise to very profound ethical, legal and social problems and challenges, given that the essence of human beings could be altered or manipulated;

(b) Artificial modification of human beings. Scientific findings in neuroscience and their application through neurotechnologies have the potential to alter certain

<sup>5</sup> Yuste, "Un paso histórico", pp. 7–8.

fundamental human characteristics, such as autonomy, moral responsibility, free will, dignity, identity, private mental life, understanding of individuals as entities bound by their bodies, bodily integrity and security;

(c) Causing physical damage or mental manipulation in human beings. Physical damage, tissue damage and impaired motor function (infringement of the right to mental integrity) could also result from invasive procedures performed to fit enhancement or brain-machine interface devices;

(d) Improper processing of neurodata and their use for purposes that are contrary to human dignity or that are not authorized by law. "Brainjacking" may involve the theft of information (violation of the right to mental privacy). In addition, viruses could be introduced or Internet-connected neural devices might make it possible for individuals or organizations (hackers, corporations or government agencies) to track or even manipulate an individual's mental experience.<sup>6</sup>

13. The Global Privacy Assembly<sup>7</sup> stresses that the processing of personal data deriving from the use of neurotechnologies raises concerns and the need to be assisted by solid and appropriate safeguards to protect the fundamental rights and dignity of individuals involved. Moreover, the possible use of neurotechnologies beyond the medical treatment and scientific research sectors in compliance with applicable sectoral and ethics standards raises further crucial considerations from a human rights perspective.<sup>8</sup>

14. In summary, despite the mental health benefits that neurotechnologies will bring, there is a fear that neurodata will not only allow us to know what people are thinking (which is not possible for now), but also to manipulate the human brain. For this reason, neurorights have recently been developed with the following aims:

(a) Preservation of a person's privacy with respect to his or her brain (a person's thoughts);

(b) The right to be as one is: the "right to the self", to one's natural cerebral identity;

(c) The right to decide for oneself, without artificial manipulation or programming;

(d) Neutral, unbiased neurotechnologies; biases should not be implanted in the human brain;

(e) Equitable access to neurotechnologies.

## **III. Neurodata**

15. Neurodata have been established as a special category of personal data that must be processed in a diligent, ethical and professional manner to ensure that individuals are protected and that their human dignity is safeguarded. Data generated by the nervous system and the brain have unique characteristics that differentiate them from all other personal

<sup>6</sup> See R. Yuste and others, "Four ethical priorities for neurotechnologies and AI", *Nature*, vol. 551 (November 2017), pp. 159–163.

<sup>7</sup> The Global Privacy Assembly held its first meeting in 1979, under the title International Conference of Data Protection and Privacy Commissioners. Today, it has become the premier global forum on the subject and has been bringing data protection and privacy authorities together for more than four decades. It builds links between the activities of more than 130 privacy and data protection authorities around the world and holds a repository of Assembly documentation and information about its past, present and future activities that is highly valued by the data protection community. For more information, see [https://globalprivacyassembly.org.](https://globalprivacyassembly.org/)

<sup>8</sup> Global Privacy Assembly, Resolution on principles regarding the processing of personal information in neuroscience and neurotechnology, adopted at the forty-sixth Annual Conference of the Assembly, November 2024. The text of the resolution is available at [https://globalprivacyassembly.org/wp](https://globalprivacyassembly.org/wp-content/uploads/2024/11/Resolution-on-Neurotechnologies.pdf)[content/uploads/2024/11/Resolution-on-Neurotechnologies.pdf.](https://globalprivacyassembly.org/wp-content/uploads/2024/11/Resolution-on-Neurotechnologies.pdf)

information. Furthermore, neurodata not only allow us to identify a person, but also offer an unprecedented depth of understanding of their individuality.

16. Neurodata are uniquely and exceptionally sensitive, have a direct and deep correlation with cognitive and affective states and reflect the personal experiences and emotions of human beings. The Global Privacy Assembly and other bodies therefore recommend that legislators and public policymakers should, inter alia, establish clear rules that protect the human dignity and identity of all human beings and guarantee respect for their fundamental rights and freedoms with regard to the processing of neurodata and the use of neurotechnologies.<sup>9</sup>

17. This ability to explore such intimate and personal aspects underscores the need for a regulatory framework that prioritizes ethics and human rights in the processing of neurodata in order to avoid potential harm that might compromise individuals' integrity or privacy.

18. In this context, it is essential to ensure that the use and processing of neurodata is governed by sound principles that protect individuals against risks such as discrimination, manipulation and invasion of mental privacy. Regulation should be used to ensure that technological advances in this area are employed responsibly and that human dignity and autonomy are respected at all times.

19. The Ibero-American Data Protection Network has stated that brain data, or neurodata, have certain characteristics, as described below:

(a) Information from the nervous system and the brain is unique and personal. In particular, each human brain is unique and allows personal identification through the anatomy of brain regions. As an identifier, the brain is as unmistakable as a fingerprint. Authors who have dealt with this subject therefore conclude that the structures of the nervous system as a whole, and of the human brain in particular, are unique to individuals and can be used to identify people;

(b) Neurodata can enable a unique depth and form of understanding of an individual and can be used predictively to discover characteristics or predispositions of which the individual might be unaware. They can also provide insight into brain processes in real time, allowing direct recording of processes associated with personality, mood, behaviours, thoughts or feelings.<sup>10</sup>

20. In 2024, the Ibero-American Data Protection Network adopted a statement on neurotechnologies and neurodata which analyses the challenges of neurotechnologies from the perspective of personal data processing.

21. In the statement, the Network:

(a) Defines neurodata and reaffirms that, when associated with identified or identifiable individuals, they should be considered personal data. It emphasizes that the brain is as unique an identifier as fingerprints or the genome and that situations of neurodiscrimination might arise because technical and scientific advances are not free of errors, leanings, biases, political or religious interpretations or prejudices. The Network therefore concludes that any processing that includes neurodata should be considered high-risk processing of personal data;<sup>11</sup>

(b) Calls for a specific framework for transparency in the processing of neurodata to facilitate public debate, ensure accountability among public and private actors and guarantee the rights of all affected persons, in the context of a complex supranational ecosystem;<sup>12</sup>

<sup>9</sup> Ibid., para. 10.

<sup>10</sup> Statement on neurodata of the Ibero-American Data Protection Network, adopted in a closed meeting of the Network's twentieth anniversary session, held in Antigua Guatemala on 25 September 2023.

<sup>11</sup> Statement of the Ibero-American Data Protection Network on neurotechnologies and neurodata within the framework of data protection regulations, adopted in a closed meeting of the Network's twentieth anniversary session, held in Cartagena, Colombia, on 29 May 2024, pp. 2–3.

<sup>12</sup> Ibid., p. 3.

(c) Demands specific guarantees on neurodata because of the risks associated with the processing of such information;<sup>13</sup>

(d) Sets out factors that must be taken into account in establishing the liability of a producer, supplier or administrator of neurotechnologies;<sup>14</sup>

(e) Recalls the proposal to create new neurorights, namely: (i) personal identity, (ii) free will, (iii) mental privacy, (iv) equitable access and (v) protection against bias.<sup>15</sup>

22. Supplementing the foregoing, the International Working Group on Data Protection in Technology (the Berlin Group) makes the following recommendations for creators or developers of neurotechnologies and anyone who collects, uses or processes neurodata:

(a) Assess the necessity and proportionality of processing neurodata in relation to the intended purpose;

(b) Ensure transparency in processing data using neurotechnologies;

(c) Build in security measures appropriate to the level of sensitivity of the data being collected and the purpose for which they will be used;

(d) Ensure privacy by design and by default.<sup>16</sup>

23. Taking into account the challenges surrounding the issue, it would be advisable to promote the prompt establishment of legal frameworks to regulate the privacy-related aspects of neurotechnologies and neurodata. Set out below is a proposal on the foundations and principles for the regulation of the use of neurotechnologies and the processing of neurodata from the perspective of the right to privacy.

# **IV. Foundations and principles for the regulation of the use of neurotechnologies and the processing of neurodata from the perspective of the right to privacy**

### **A. Foundations**

24. The rapid advances in neurotechnologies and their capacity to capture, process and analyse neurodata pose ethical and legal challenges that transcend national borders and demand a regulatory response combining rights protections and technological development. Set out below are the essential foundations and principles, from the perspective of the right to privacy, for the creation of a draft model law to serve as a tool for harmonization at the international level. The model not only establishes minimum standards for the safe and ethical use of neurotechnologies, but also constitutes a reference on the basis of which countries can develop local regulations suited to their legal and social contexts.

25. The model law should incorporate the relevant guidelines and directives on the subject and related issues issued by organizations such as the Organization of American States,<sup>17</sup> the

<sup>13</sup> Ibid., pp. 4–5.

<sup>14</sup> Ibid., p. 5.

<sup>15</sup> Ibid, pp. 5–6.

<sup>16</sup> See International Working Group on Data Protection in Technology, working paper entitled "Emerging neurotechnologies and data protection", presented at the seventy-fourth meeting of the Working Group, held on 18–19 November 2024.

<sup>17</sup> Organization of American States, Inter-American Declaration of Principles Regarding Neuroscience, Neurotechnologies, and Human Rights, adopted in March 2023 by the Inter-American Juridical Committee, an advisory body of the Organization of American States; Updated Principles on Privacy and Personal Data Protection, with annotations, adopted on 9 April 2021 by the Inter-American Juridical Committee (the Principles were approved by the General Assembly of the Organization of American States in November 2021); and Declaration of the Inter-American Juridical Committee on Neuroscience, Neurotechnologies and Human Rights: New Legal Challenges for the Americas, adopted in August 2021 by the Inter-American Juridical Committee.

United Nations Educational, Scientific and Cultural Organization (UNESCO), <sup>18</sup> the Organisation for Economic Co-operation and Development, <sup>19</sup> the Ibero-American Data Protection Network,<sup>20</sup> the Latin American and Caribbean Parliament,<sup>21</sup> the Global Privacy Assembly<sup>22</sup> and the International Working Group on Data Protection in Technology (the Berlin Group).<sup>23</sup>

26. Set out below are the definitions and principles that should be included in the proposed model law.

## **B. Definitions**

27. In the model law, it is useful to define the following terms:

(a) Personal data: any information linked to, or that can be associated with, one or more identified or identifiable natural persons;

(b) Sensitive personal data: information that affects the privacy of the subject or that, if used improperly, might lead to discrimination against the subject; such data include those that reveal the subject's racial or ethnic origin, political leanings, religious or philosophical beliefs or membership in a trade union, social or human rights organization or organization that promotes the interests of any political party or that upholds the rights and guarantees of opposition parties, as well as data relating to health and sexual life, biometric data and neurodata.

(c) Neurodata: information obtained from a person's central or peripheral nervous system through the use of neurotechnologies;

(d) Neurorights: category of human rights that seek to guarantee dignity and fundamental rights in the field of research and use of neurosciences and neurotechnologies;

(e) Neurotechnologies: any technology that records, interprets, alters or interferes with brain activity using any optical, electronic, magnetic or nanotechnology technique that allows understanding of brain processes such as vision, sensations, perceptions, behaviour, ideas, memory, emotions, consciousness, imagination, decisions or the mind;

(f) Invasive neurotechnologies: techniques that record or alter brain activity from inside the brain, involving intrusive medical procedures in the human body;

<sup>18</sup> United Nations Educational, Scientific and Cultural Organization, Neurotechnologies and Human Rights in Latin America and the Caribbean: Challenges and Public Policy Proposals, 2023; Universal Declaration on Bioethics and Human Rights, adopted by acclamation by the thirty-third session of the General Conference on 19 October 2005; International Declaration on Human Genetic Data, adopted by acclamation by the thirty-second session of the General Conference on 16 October 2003; and Universal Declaration on the Human Genome and Human Rights, adopted by acclamation by the twenty-ninth session of the General Conference on 11 November 1997.

<sup>19</sup> Organisation for Economic Co-operation and Development, Recommendation on Responsible Innovation in Neurotechnology. The official text is available at [https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0457.](https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0457)

<sup>20</sup> Ibero-American Data Protection Network, Statement on neurotechnologies and neurodata within the framework of data protection regulations, adopted in a closed meeting of the Network's twentieth anniversary session, held in Cartagena, Colombia, on 29 May 2024; and Statement on neurodata, adopted in a closed meeting of the Network's twentieth anniversary session, held in Antigua Guatemala on 25 September 2023.

<sup>21</sup> Latin American and Caribbean Parliament, Model Law on Neurorights for Latin America and the Caribbean (Panama, 19–20 May 2023).

<sup>22</sup> Global Privacy Assembly, Resolution on principles regarding the processing of personal information in neuroscience and neurotechnology, adopted at the forty-sixth Annual Conference of the Assembly, November 2024. The text of the resolution is available at [https://globalprivacyassembly.org/wp](https://globalprivacyassembly.org/wp-content/uploads/2024/11/Resolution-on-Neurotechnologies.pdf)[content/uploads/2024/11/Resolution-on-Neurotechnologies.pdf.](https://globalprivacyassembly.org/wp-content/uploads/2024/11/Resolution-on-Neurotechnologies.pdf)

<sup>23</sup> International Working Group on Data Protection in Technology, working paper entitled "Emerging neurotechnologies and data protection", presented at the seventy-fourth meeting of the Working Group, held on 18–19 November 2024.

(g) Non-invasive neurotechnologies: techniques that record or alter brain activity from outside the skull;

(h) Processing: any activity carried out using personal data.

### **C. Principles**

28. Fundamental principles are the backbone of any regulation of neurotechnologies and neurodata processing, constituting the ethical and legal basis that guides their design, implementation and interpretation. These principles not only provide coherence in the regulatory framework, but also guide the proper application of its provisions, ensuring a balance between technological progress and the protection of human rights. By establishing values such as mental privacy, ethics and non-discrimination, the regulations are guaranteed to be suited to current and future challenges and promote respect for human dignity in a fair and effective manner. The principles act as essential guidelines for resolving conflicts, filling regulatory gaps and ensuring comprehensive protection of neurodata in all contexts.

29. In addition to the general principles governing privacy and data protection in general, more specific principles are proposed below.

#### **Human dignity**

30. Dignity, as the core value inherent to human beings, is inviolable. Practices that are contrary to human dignity should not be permitted.

31. Everyone should have access to the progress made in neurotechnologies, and the dignity and rights of every person should be respected in that context.

32. In the design, development, implementation, commercialization, evaluation and use of neurotechnologies, the State should promote an approach rooted in respect for human dignity and human rights.

### **Neural data as highly sensitive personal data**

33. Neurodata are highly sensitive personal data. The persons responsible for or in charge of the processing and use of neural data should adopt enhanced privacy and security measures, ensuring limits on the application of decoding techniques that make it possible to identify a person or render him or her identifiable, especially for databases or datasets that are shared with third parties. The State should promote measures to ensure the control, security, confidentiality and integrity of neurodata.

### **Mental privacy and consent for processing neurodata**

34. Any development or use of neurotechnologies shall be undertaken for the purpose of contributing to the right of every person to enjoy a dignified life and the benefits of scientific and technological progress, while respecting, inter alia, rights related to privacy and the proper processing of personal data.

35. The prior consent of the data subject is a prerequisite for the collection and processing of neurodata. Such consent must be free, informed and specific and must be given expressly and unequivocally for a lawful and specific purpose. Any consent given may be revoked at any time, except where the relevant neurodata has been irreversibly separated from identifying information. Specific protection measures are required when the data subjects belong to specially protected groups such as children, persons with disabilities, older persons or persons deprived of liberty.

### **Ethics and human rights protections by design and by default in the development and use of neurotechnologies**

36. A human rights-based approach should be promoted in the development of neurotechnologies, with the aim of guaranteeing comprehensive protection and respect for human rights from the outset of the design process of neurotechnologies, at the research, implementation and commercialization stages and in their evaluation and use.

37. Human rights protections by design implies, inter alia, compliance with the requirements set out below.

38. Prior to a neural study or research project or the design and development of neurotechnologies or neural products, a human rights impact assessment should be conducted in order to establish an effective system of risk management and internal oversight to ensure that human rights are protected.

39. Such impact assessments must include, as a minimum, the following information:

(a) A detailed description of the neural data processing operations involved in the study or research project;

(b) An assessment of the specific risks of violating the rights and freedoms of individuals;

(c) Preventive measures to address and mitigate the risks of violating fundamental rights;

(d) The checks that will be done to verify the relevance, timeliness and effectiveness of the measures referred to above.

40. Before neurodata are collected, and throughout their life cycle, a range of preventive measures, including technological, organizational, human and procedural, should be taken to avoid violations of fundamental rights or the misuse of neurodata or neurotechnologies.

41. Ethics by design and by default should permeate the design, development and use of research products or processes involving the brain, neurotechnology or neurodata.

42. All studies, trials or research protocols must take into consideration ethical standards and guidelines for research.

### **Precautionary principle**

43. If there are elements associated with the research or use of neurotechnologies or neurodata that might give rise to serious and irreversible damage to human beings or human dignity, even when there is no scientific certainty of the causal effect, precautionary measures must be taken to prevent such damage.

44. The precautionary principle also applies when the risk or severity of the damage that might be caused is not known in advance.

### **Demonstrated accountability and safety in neurodata processing**

45. In the processing of neurodata, useful, timely, relevant, effective and demonstrable measures for regulatory compliance must be adopted and implemented, in particular measures to prevent any unauthorized or improper access to or distribution, supply, use, manipulation or destruction of neurodata.

46. All security measures should be subject to ongoing review, evaluation and improvement.

#### **Non-discrimination**

47. Neurodata and neurotechnologies must not be used for purposes of discrimination, stigmatization or violation of the rights and freedoms of individuals.

### **Effective protection of the rights of individuals in the processing of neurodata**

48. The State must guarantee that mechanisms are in place to ensure the effective protection of the rights associated with the processing of neurodata. It must also guarantee access to legal remedies and full reparations in the case of human rights violations.

## **V. Recommendations**

49. **In the light of the foregoing, the Special Rapporteur urges States to:**

(a) **Promote the regulation of neurotechnologies and the processing of neurodata. It is essential that each country develop a specific regulatory framework for neurotechnologies and neurodata, given their potentially profound impact on privacy, human dignity and fundamental rights. Regulation must anticipate the associated risks and ensure the safe, ethical and responsible use of these technologies;**

(b) **Incorporate the foundations and principles for the regulation of the use of neurotechnologies and the processing of neurodata from the perspective of the right to privacy suggested in the present report. The foundations and principles set out in the present report, including the protection of human dignity, informed consent, ethics by design, the precautionary principle and non-discrimination, should be integrated into national legal frameworks. These principles will ensure a balance between technological innovation in neurotechnologies and the protection of human rights, with a particular focus on privacy and the proper treatment of neurodata;**

(c) **Promote ethical practices in the use of neurotechnologies. It is essential to establish guidelines and oversee practices that guarantee the ethical use of neurotechnologies and ensure the proper processing of neurodata as highly sensitive information. These practices must prevent any improper use that could compromise privacy or give rise to discrimination;**

(d) **Promote education on neurotechnologies and neurodata. To ensure informed use of these technologies, States should promote public education on the benefits and risks associated with neurotechnologies. This will enable people to better understand their impact, make conscious decisions about their neurodata and demand that their rights be respected in this new technological era.**